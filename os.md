# CS 4410

这是CS 4410的预习笔记。本课程讨论的问题是操作系统。

操作系统是一个非常特殊的、最低级的软件。它的目标是让多个程序能够一起执行、让多个程序分享内存或与输入输出设备交互等等。操作系统通过*虚拟化*完成这些任务，即提供给程序一系列虚拟的资源，自己把这些虚拟资源对应到实际存在的物理资源，从而方便地让一套硬件上能运行多个程序。因此，操作系统有时又称虚拟机。通过虚拟化资源，操作系统能让程序并行执行。通过建立一套文件系统，操作系统能有效管理内存。通过建立网络通信，操作系统能够让分布式系统成为可能。

为了方便程序利用操作系统的资源，操作系统会提供一系列标准接口，这些接口称为**系统调用**。操作系统还会通过虚拟化CPU和虚拟化内存，定下程序执行的规则，综合管理其拥有的资源。

## 第1章 虚拟化

本章我们主要讨论处理器和内存的虚拟化。

### 1.1 处理器虚拟化

#### 1.1.1 进程

一个正在执行的程序称为**进程**。每个进程都有其内存，它们都是由地址空间指明的。进程需要被创建、消灭、等待和控制。一套硬件也可以运行大量的进程，而操作系统通过虚拟化处理器，即把程序抽象为进程，以进程为单位管理处理器上程序的运行，实现这个功能。时间分享（即某个进程运行一会儿，再让另一个进程运行一会儿，再回到第一个进程的策略）和空间分享（资源存储多份）是主要的虚拟化方式，而进程的调度策略是操作系统中实现的核心内容。

操作系统在启动进程时，首先会给进程分配地址空间，之后它会把存在磁盘上的程序导入内存。然后它会建立进程的调用栈和内存堆，在必要时通过文件系统等打开输入输出，并把控制权转交给新创建的进程，让它从起始位置开始运行。在进程运行时，进程可以在运行、待命、受阻三个状态间切换。当进程完成时，操作系统会负责把程序的调用栈清除（堆不一定），关闭输入输出。操作系统会通过维护进程列来管理进程。

#### 附录 在Unix操作系统中创建和关闭进程

Unix系统中创建进程的系统调用是fork和exec。fork复制了一个当前的进程，但还没开始执行任何事务，而exec则把另一个程序的代码拷到当前进程来执行。把创建进程的命令分成两部分是为了方便在fork之后、exec之前，可以重定向执行的目标地。wait系统调用则会确保父进程在子进程结束之后再结束。

Unix系统中关闭进程的命令是kill。kill通过发送某些信号的方式让进程终止。使用kill时要多加小心，切勿把有用的进程也关闭了。

Unix系统中管理进程的方式是信号。常用的信号有2号（SIGINT），9号（SIGKILL），14号（SIGALARM）等等。信号与系统调用最大的不同是，系统调用由进程发出，与硬件有关，由操作系统处理，而信号由操作系统发出，与硬件无关，是为了控制进程继续执行与否，由用户和软件处理。

#### 1.1.2 有限直接执行

进程是通过“有限直接执行”的方式执行的。大量的行动不能让进程自己执行，比如输入输出、访问内存等。为此，处理器中进程运行的模式应有两种：用户模式和内核模式。比如，用户模式中无法输入输出，而只有内核模式可以。用户模式下进程想输入输出，启动或终止进程，因page fault需要永久内存，访问文件系统，或打扰其他进程时，必须进行系统调用。

系统调用绝不能像函数调用一样直接把程序跳到某处。对于任何一种系统调用，操作系统都必须特殊地指明它的trap handler，硬件就会知道当异常情况发生时自己应该干什么。操作系统启动时，会初始化这张trap表，以给出那些系统调用的特殊地址。trap表中的地址还是间接的地址（称为系统调用号），能起到保护的作用。trap表的创建和访问都只有操作系统才能完成。

系统调用时，进程会经历trap过程，以进入内核模式。为了重新返回正常执行，程序必须从trap中退出。进入trap时，处理器（硬件）会把程序的PC、调用栈寄存器等许多重要的寄存器存到一个每个进程都有的内核栈中，访问trap表，找到要做的操作。而退出trap时，这些栈中存储的值都会被返回，进程返回原运行状态。

另一个需要操作系统通过有限直接执行的方式管控的是在进程之间不断切换的操作，这是为了实现时间分享，制造同一套硬件可以运行多个进程的假象。可以期待进程定时进行系统调用，这样操作系统就可以在调用期间把该进程暂停，但这种期待对于某些危险的进程而言是不现实的（重启？）。更安全的方式是给每个进程设置一个时间限制，一旦超时进程会中断，控制权将转交给系统。

操作系统启动时，必须向硬件指明中断的handler，以处理这种情况。操作系统也必须在系统启动之前指明每个进程的时间限制。硬件应该配合处理中断，包括保存进程的状态等。然后操作系统会更改环境，即选择执行另一个进程。这种调度选择的过程我们会在下一小节中讲到。

#### 1.1.3 进程调度

进程的周转时间是指其完成时刻减去到达系统的时刻，而进程的响应时间是指其开始执行时刻减去到达系统的时刻。

基础的调度策略是先到先得(FIFO)，但当某个耗时很久的进程阻挡在其他进程之前时，系统就有卡顿（周转时间长）的问题。另一种调度策略是最快者优先(SJF)。如果所有进程同时到达，最快者优先是最优的调度策略，然而如果进程不同时到达，卡顿的问题则依然存在。策略三是最快结束者优先(STCF)，这种策略在进程不同时到达的情况下成了最优。

以上的策略是在没有时间分享的情况下讨论的。然而，时间分享给了我们更充分的调度工具。我们可以让每个进程只运行一小会儿（RR），这样所有进程都能有较短的相应时间，但周转时间会受到很大影响。每个进程可以运行的时间周期非常重要，这个周期要充分长，以允许进程有实质性动作，但为缩短响应时间也不能太长。

输入输出、系统调用等会把CPU空出来。在进程调度时，操作系统就应该在CPU空出来的时候运行其他进程，以统筹的方式提高处理器效率。

一个需要解决的重要问题是，操作系统怎么能在不运行进程，从而不知道进程运行时间的情况下完成调度呢？操作系统是通过预测进程运行时间的方法完成的。它建立了一个叫**多层反馈队列**(MLFQ)的启发式的数据结构。这个数据结构把进程组合进一组队列，不同的队列有不同的优先级，同一队列有相同的优先级。MLFQ有如下5个规则：（1）处理器会运行优先级最高的那个队列，（2）但每个队列中的那些进程按RR运行。队列的优先级随观察到的结果灵活变化。（3）每个进程刚进入系统时有最高的优先级。（4）如若此进程用光了属于它的那一小块时间则其优先级降低，哪怕此进程在中途离开了CPU。（5）每隔一段时间优先级全部归零。

另一种实用的进程调度策略是**比例调度**，即保证每个进程都占有一定比例的CPU时间。在每个时间周期内，操作系统给每个进程赋予一个权重，以*随机*方式加权选出本周期运行的进程。每个进程还可以给它们的子进程加权，且进程权重也不是一成不变的。这种方法既简单，又可以在进程数较多时保证调度的公平性。

#### 附录 Linux系统中的进程调度

现代Linux系统使用了一种称为“**完全公平调度（CFS）**”的进程调度方式。它的方法是测量每个进程的虚拟运行时间(vruntime)，拥有最低vruntime的进程将会被提高执行权限，这个执行权限就是著名的nice值。如果进程少则每个进程每个周期时间多，如果进程多则反之，但每个进程周期有个最低下限，这样就保证切换频繁，相对公平，同时通过设置进程切换周期下限，且设置vruntime权限，保证进程周转时间较小。

因为进程的个数可能远超千个，CFS为加快调度速度，内部的进程列按照vruntime用红黑树存储。对于输入、输出和睡眠的进程，vruntime做额外处理。

#### 拓展 多核处理器中的进程调度

多核下进程调度比单核还要困难，同样有大量的优化思路涌现出来。

思路一：单队列调度(SQMS)。所有核共用一个进程队列，每个进程运行时加锁。这样很简单，却无法适应核数目的增长，同时还无法让一个进程尽可能只在一个核上运行。为此需把一些进程移植到与用原本方法不同的核上运行，优化很困难。

思路二：多队列调度(MQMS)。每个核维护一个进程队列。这样能适应核的增长，却容易出现核负载不均衡的现象，同样需要把某些进程移植到另一个核上运行，优化也不容易。

### 1.2 内存虚拟化

每个进程都有一个地址空间作为其可使用的内存。代码、栈和堆都存在这个地址空间里。栈和堆从两个方向逐渐把地址空间填满。为了让各个进程互不干扰地分享内存，操作系统需要通过建立地址表的方式虚拟化内存。虚拟内存系统必须是不透明的、高效的、安全的。

#### 1.2.1 地址翻译

操作系统给每个进程的地址都是虚拟的，而实际的地址只有操作系统知道。操作系统通过地址翻译把物理地址翻译成每个进程的虚拟地址，以构造每个进程独享内存的假象。由于地址甚至在程序运行时也可以更改，这种分配地址的方法称为动态分配法。为了保证进程访问的地址不越界，操作系统需要存储表示进程地址开始处的寄存器和进程地址结束处的寄存器，并在进程越界时终止进程，而硬件则需要提供这些寄存器，并不允许用户模式的任何进程修改这些寄存器，从硬件角度保证安全。由此可以看到，虚拟内存的实现也体现了有限直接执行思想。

于是，在任何一个进程开始时，操作系统还要负责给进程分配一块地址空间。当进程终止时（无论正常还是非正常），操作系统要负责把这块地址空间释放。在进程切换时，操作系统还要妥善地把属于那个进程的内存保存起来。在进程发生异常时，操作系统要提供额外工具(handlers)处理这些异常。

#### 1.2.2 分页分段

为了更大限度地利用自由空间，在物理内存中可以把代码、栈和堆分段存储。因此存储一个进程的所有内存需要三对寄存器标志其内存的起始点、终止点，一个额外的寄存器标志内存生长方向、另一个额外寄存器标志可以对此内存访问的权限，包括读、写和执行。内存地址由每段的基础位置和offset组成。找寻段地址是很容易的事情，只需把段号码加上offset即可。如若超出合法内存访问范围，操作系统会终止进程访问，称为发生段错误（segmentation fault），这就保证了进程安全。

通过标记段落权限，分段还有更多的好处，比如**写入时复制**(copy on write)，即不急着复制内存，只复制地址表，两张地址表指向同一套地址，且这些地址都只赋予读权限。当需要写入时，再执行复制，分离地址表。COW策略在fork函数实现时起到了提高性能的作用。

分段方便了进程管理，但也会在每个段中留下大量的自由空间，可能会造成浪费。且如果段落的大小不一致，浪费的空间由于狭小且不连续更难被利用。更简单、有效和灵活的方法是让段落大小一致，这种分段方法称为分页。操作系统通过查询页码表的方式来找到虚拟地址的实际地址。*每个进程都有一个页码表*，因为为了内存虚拟化，每个进程的虚拟地址对应的物理地址都不相同。找寻地址只需把虚拟页码加上offset即可。

为了存下每个物理内存地址的虚拟地址，页码表需要变得非常庞大，因此操作系统必须把它们放在内存里。为了方便存储页码，系统需要为每一页存储一些额外比特：有效比特、保护比特、使用比特（是否出现在内存中）、脏比特、访问比特等等是常见的额外存储内容，这样操作系统就能随进程需要增减页码表了。

然而即使这样页码表还是太大了。缩小页码表的算法就变得很重要。最简单的就是增大页码的大小，但这样会增大寻址时间，造成内存浪费。第二种方式是把分页和分段结合起来——*每个进程分成多个段，每段都有一个页码表*，由于段内所有内存都是连续的，很容易在页码表中标记有效页码的起点和终点，就不用在页码表中存储无效页码了。但分段的解决方案比较复杂，且会在段外浪费很多不连续内存。页码表过大问题的现代解决方案是使用**多层页码表**。存一张页码表的页码表，第一层页码表中没有的页码在第二层中不分配内存。这样访问页码很快捷，也不用为没有使用的内存分配页码了。另一种解决该问题的方案称为**逆页码表**。与其为每个进程的每个虚拟地址建一条表的记录，不如为每个物理地址建一条表的记录，只不过这条记录还需额外记下进程的PID罢了。可以用哈希表方便通过进程PID和虚拟地址查询实际地址的反向查询，这样也能节省空间。

另一个问题是，在分页模式下访问一次内存要先访问一次页码表，等于访问两次内存！为了加快页码表访问，**翻译前视缓冲器**(TLB)成为了必需。TLB就是地址翻译缓存，它的出现让分页虚拟内存成为可能。带有TLB的地址翻译过程如下：首先，从虚拟地址获取虚拟页码，并把它扔进TLB。如果通过，则可从TLB获取实际地址，到内存中去访问。如果未通过，则硬件(x86)或者软件(RISC)需浏览地址表，慢慢找到实际地址，并更新TLB。

TLB是一种完全结合型缓存。通常TLB有一个有效位、保护位、地址空间ID、脏位等等。当进程切换时，TLB要么刷新，要么改变一个比特来标记该地址关系属于哪个进程。

#### 1.2.3 虚拟内存和内存替换

虚拟内存的“虚拟”除了指进程读到的地址不是实际地址以外，还指计算机可利用的内存（临时内存）比实际的内存还多。机制就是对硬盘（永久内存）上的地址也进行分页。当进程需要访问不在内存（临时内存）的地址时，硬盘中的相应内容需要调到内存，而内存中某些内容必须被替换以腾出空间，这个过程称为处理page fault。进程无法单独处理page fault，必须抛出异常由操作系统来完成。

选择无用内存替换到硬盘又是一个困难的问题，而这个问题与选择无用缓存替换到内存中很类似，这类问题称为内存替换。常见的内存替换规则（算法）有：随机算法、先入先出算法、最不频繁使用算法(LFU)、最近最少使用算法(LRU)。LRU在大部分的情形下都最接近最优，尽管随机算法可以避免某些边角情形。严格的LRU几乎是不可实现的，所以我们只能近似LRU。硬件上可以为内存内容添加一个使用比特，每次使用该内存时使用比特修改为1，操作系统挑一个使用比特为0的内存清空，并周期性地、轮流地把所有内存的使用比特清零，这种算法称为钟表算法。

在内存替换中最需要避免的情况称为系统颠簸(thrashing)，这是指由于进程循环调用数量多于内存（缓存）帧数目的页，导致进程几乎全部的运行时间都耗费在内存替换上的现象。有的时候增加内存帧数还会让系统颠簸更严重（这种现象称为Bealy异常，只有用栈内存替换方法才会避免这种异常），所以不能仅靠增加内存帧数来解决系统颠簸。解决的方法是使用工作集模型，即周期性记录下每个进程需要的页数（工作集），如果所有进程需要的页数总和大于内存（缓存）中可提供的帧数，则暂停一个进程。工作集的大小需要操作系统实时预测，并灵活根据page fault的频率调整。

#### 1.2.4 自由空间分配

分段存储方法会在有用内存外留下大量的自由空间，如何合理分配这些自由空间，让它们不要碎片化，也是一个重要的问题。基本的方法是一分为二（malloc时）、合二为一（free时）。为了方便这两个操作，在内存获取和释放时，一般还要记录有关本次内存分配的概况信息，比如本内存块的大小。当然选择适合的内存块也有很多策略，比如最小块、最大块、第一块、下一块等，甚至把常用的相同大小的内存分开存储以加快常用内存的访问速度。

#### 附录 Linux内存系统设计

Linux系统的地址空间为32位或64位。四分之三的空间归用户，四分之一的空间归操作系统。内核逻辑地址存储页码表、系统调用代码、对每个进程建立的内核栈等等。内核虚拟地址是为了解决访问内存外地址的问题的。

目前通用的x86型Linux系统的页码表为64位，设了4层页码表以层层寻址。Linux传统上支持4kB地址表，尽管现在也支持使用2MB甚至1GB为大小的地址表。Linux页码替换的算法是2Q算法：维护一个活跃队列和非活跃队列，需替代的进程是非活跃队列的最后一个，活跃队列的最后一个会被周期性地移到非活跃队列，活跃队列的长度是总页码缓存大小的三分之二。这是为了解决大文件访问的问题。

### 第1章小结

问题 | 解决方案
-|-
多个程序需要同时执行，却只有一个处理器 | 虚拟化处理器，程序抽象为进程，进程间不断切换，时间分享
虚拟化处理器时进程间要互相分隔保证安全 | 输入输出、访问内存等关键操作时进程必须系统调用
不同进程都需要尽快处理完毕无卡顿（进程调度） | FIFO, SJF, STCF, RR, MLFQ, 比例调度，CFS
多核处理器中进程调度 | 单队列SQMS、多队列MQMS、移植
进程的内存要安全分配、分隔 | 虚拟内存（虚拟地址、地址表）、将进程地址分页分段、页码+offset存储
自由空间高效分配 | 一分为二、合二为一、最小块、最大块、第一块、下一块、分开存储常用大小内存
页码表访问内存次数变多 | 使用TLB，加快简单情形访问
页码表存储空间过大 | 增大页码表大小、分页分段结合、多层页码表、逆页码表
利用内存以外的存储空间 | 通过虚拟内存为硬盘分配页码表
某些内存需被替换到硬盘上或某些缓存需要被顶替（内存替换） | 随机、FIFO, LFU, LRU，近似LRU、钟表算法
内存替换导致系统颠簸 | 工作集模型，及时暂停某些进程
处理page fault | 操作系统系统调用

## 第2章 并行

本章我们主要讨论一个进程是如何被剖分成多个线程，从而在多个处理器上并行运行的。

### 2.1 线程

一个进程可以分成多个**线程**，这些线程拥有不同的PC、不同的内存栈等等，唯一相同的是它们共享内存地址空间，即它们只有一套数据（特别地，所有线程共用一个堆）。如果几个线程在同一个处理器上运行，线程之间必须不停切换，只是切换时不需要单独存储原有线程的地址空间了。

当进程运行时，线程运行的顺序是不可确定的——都是由操作系统调度器决定（操作系统调度不仅决定进程调度，也决定线程调度）。任何一个线程在执行到任何一个语句时都可能被中断切换到下一个线程。由于线程共享内存，线程可能会阻塞对方完成其应有的任务，这种情况称为竞争执行。为了防止竞争执行，我们必须限定某线程的某段代码执行时不能被中断，即保持这段代码的互斥性（原子性），这种被原子化的代码称为事务(transaction)。

### 2.2 锁

#### 2.2.1 锁的实现

实现事务原子化的基础机制是锁，它是一个由硬件和操作系统提供给软件的接口。当某线程第一个请求某锁时，它将拥有这把锁，然后执行被锁住的代码。其他线程若想获得*这把锁*（可以同时有很多锁存在），执行被*这把锁*锁住的代码，则必须等待第一个线程退出。当该线程退出时，所有等待线程中的一个将会被通知，它将获得这把锁，从而可以执行它被锁住的代码。通过锁可以保证关键代码的原子性（异步执行），从而在操作系统混乱不可预知的调度下保证关键代码的执行有序。

实现锁的关键之处在于实现互斥执行。最简单的互斥执行方式是暂停所有对该线程的中断，但很不幸的是，坏线程会利用这点运行无穷循环，从而导致系统崩溃，因此这种锁只在操作系统内部有少量的使用。第一个有效的锁是Test & Set自旋锁，即通过硬件支持把test & set变成一个不可拆分的原子表达式，这样就不会在线程运行到关键时刻时有其他线程被调度进来。自旋锁不是公平的锁，在单机上非常浪费，但在分布式系统上如果关键时刻做的操作不多，性能还不错。与之类似的算法还有compare & swap, load linked & store conditional, fetch & add等等（代码可以参考附录），这些都是自旋锁。

自旋锁在性能上有巨大的缺点——其他线程做死循环浪费了大量的钟周期。除了fetch & add以外的其他自旋锁还不能保证每个线程都会被执行（不公平）。为了不用死循环实现锁，操作系统必须提供软件支持，即给线程提供某些系统调用，使其能有限地控制自己或其他线程的调度——要么把自己调出去（wait或park或sleep），要么宣布某些把自己调出去的线程可以执行(notify或unpark或wake)。为了确保每个想要锁的进程最终都会执行，锁还应该维护一个线程队列，挨个执行线程队列中的线程，确保锁对所有线程的公平性。将自旋锁和wait锁结合起来有时能获得更好的性能，比如Linux的futex锁就是两者的一个结合。

锁实现中一个特殊的竞争执行是wakeup/waiting竞争执行，即A线程醒来时B线程正在准备睡觉，导致B线程无法收到锁已经被释放的信息，B很可能永远睡下去，无法获得锁。解决的方法是操作系统需提供一个新系统调用，让B线程能通知操作系统它将准备睡觉，当A线程广播其释放锁的信息时，B线程可跳过睡觉步骤，直接尝试得锁。

#### 2.2.2 以锁为基础的并行数据结构

为线程加锁可以让数据结构线程安全。本节我们会讨论如何为一个并行数据结构加锁使之线程安全，且能利用并行提高运行效率。

最简单的并行安全机制就是给所有的重要代码都加锁。一种叫监视器的设计方式甚至让所有与该对象有关的方法使用时自动加锁。不幸的是，加锁的成本很高，尤其在分布式系统上还与网络连接有关，对性能有很大损失。我们以并行安全的计数器为例，阐述一种更高效的可以用在分布式系统上的用锁方法，这种计数器称为近似计数器——每台机器上都有一个计数器，它们自己计算时不停地加锁，但它们都会定时地向一个总计数器汇报（自然汇报的过程需要另外加锁）。总计数器的值是近似值，汇报的频率越高，总计数器的值越准确。这样把计算的工作分担到了各台机器上，又尽可能减少了各台机器之间的通信，提高了分布式系统的性能。

在设计并行安全的数据结构时，我们必须注意（1）加很多锁有时会适得其反，因为加锁是有成本的。（2）一定要注意所有线程可能的起始点和终止点，用锁把好每一道关口，尤其在异常之处绝对不能忘记释放锁。（3）只有当性能问题出现时我们才需要考虑解决它，正确比性能更重要。

### 2.3 条件变量

在多线程编程中，我们经常需要等到某些条件成真之后再继续执行，而条件变量就是实现这种需求的机制。条件变量有两个语句：wait和signal。当某线程走到某条件变量的wait时，它会自动睡眠，直到另一个线程走到该条件变量的signal，则原线程才会继续执行。条件变量必须与锁一并使用，使用条件变量的wait（可选signal)前必须上锁，否则会出现wakeup/waiting竞争执行。当wait执行时，它会释放这个锁，而当正在wait中的线程被signal唤醒时，它会重新得锁。条件变量使用时还应注意用while循环包裹条件变量。在Java当中，条件变量称为wait/notify机制。

条件变量能够解决很多问题。join问题是指让父线程生成子线程，且让子线程结束后父进程再结束的问题，这个问题可以用条件变量解决，且应该用一个普通变量done协助完成。producer/consumer问题（或称bounded buffer问题）是指一类线程为producer，一类线程为consumer，producer往有限的缓冲区存储数据，consumer从缓冲区拿出数据，要保证这种操作线程安全的问题。可以使用两个条件变量和一个公用互斥锁解决这个问题。

条件变量实现中会遇到两个问题：第一，当线程1等待时，线程2发了信号，是线程1应该立即执行，还是线程2应该执行完其剩余的内容？前者称为Hoare semantics，而后者称为Mesa semantics。现代大部分系统采用的都是Mesa semantics，尽管Java语言实现监视器的synchronized方法与两者都有[不同](https://cseweb.ucsd.edu/classes/sp16/cse120-a/applications/ln/lecture9.html)。第二个问题称为条件覆盖。当有多个线程等待，且另一线程发送信号时，这多个线程中的哪一个有权利被唤醒？Lampson和Redell认为，所有的线程都应该被唤醒，先到先得，即把signal换成broadcast（POSIX），或把notify换成notifyAll（Java）。

### 2.4 信号量（Semaphore）
