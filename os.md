# CS 4410

这是CS 4410的预习笔记。本课程讨论的问题是操作系统。

操作系统是一个非常特殊的、最低级的软件。它的目标是让多个程序能够一起执行、让多个程序分享内存或与输入输出设备交互等等。操作系统通过*虚拟化*完成这些任务，即提供给程序一系列虚拟的资源，自己把这些虚拟资源对应到实际存在的物理资源，从而方便地让一套硬件上能运行多个程序。因此，操作系统有时又称虚拟机。通过虚拟化资源，操作系统能让程序并行执行。通过建立一套文件系统，操作系统能有效管理内存。通过建立网络通信，操作系统能够让分布式系统成为可能。

为了方便程序利用操作系统的资源，操作系统会提供一系列标准接口，这些接口称为**系统调用**。操作系统还会通过虚拟化CPU和虚拟化内存，定下程序执行的规则，综合管理其拥有的资源。

## 第1章 虚拟化

本章我们主要讨论处理器和内存的虚拟化。

### 1.1 处理器虚拟化

#### 1.1.1 进程

一个正在执行的程序称为**进程**。每个进程都有其内存，它们都是由地址空间指明的，其中的一部分存储着本进程的代码。进程同时还有自己的寄存器、PC、sp等等，以及需要管理其当前打开的文件。进程需要被创建、消灭、等待和控制。一套硬件也可以运行大量的进程，而操作系统通过虚拟化处理器，即把程序抽象为进程，以进程为单位管理处理器上程序的运行，实现这个功能。时间分享（即某个进程运行一会儿，再让另一个进程运行一会儿，再回到第一个进程的策略）和空间分享（资源存储多份）是主要的虚拟化方式，而进程的调度策略是操作系统中实现的核心内容。

操作系统在启动进程时，首先会给进程分配地址空间，之后它会把存在磁盘上的程序导入内存。然后它会建立进程的调用栈和内存堆，在必要时通过文件系统等打开输入输出，并把控制权转交给新创建的进程，让它从起始位置开始运行。在进程运行时，进程可以在运行、待命、受阻三个状态间切换，切换由进程调度管理。当进程完成时，操作系统会负责把程序的调用栈清除（堆不一定），关闭输入输出。

操作系统需要通过多个数据结构来管理进程，尤其是在某些进程不在使用处理器时，操作系统要确保该进程的全部信息被妥善存储，以便恢复。操作系统首先要存储一张进程表，对每个表中的进程要存储（当其待命或受阻，需要上下文切换时）其寄存器上下文(context)、进程状态、内存地址、进程ID(pid)、父进程、打开文件等信息。这个信息单元称为进程控制块(PCB)。

#### 附录 在Unix操作系统中创建和关闭进程

Unix系统中创建进程的系统调用是fork和exec。执行fork系统调用后，操作系统生成了一个与当前进程一模一样（指寄存器、PC、sp等等都一模一样）的进程。该进程与原进程的区别只有（1）pid不同（2）fork对父进程返回子进程pid，而对子进程返回0。而exec则把另一个程序的代码、调用栈、寄存器等拷到当前进程来执行。把创建进程的命令分成两部分是为了在Shell的实现中，便于在fork之后、exec之前重定向执行上下文，如输入输出地址等。Shell可以把默认的输出文件描述符（标准输出）改为需要重定向的文件描述符，实现重定向（">""<"）。Unix的pipe系统调用（即"|"）也是通过在fork和exec中间插入重定向实现的。wait系统调用则会确保父进程在子进程结束之后再结束。

Unix系统中管理进程的方式是信号，任何进程A都可以发送信号。信号是通过kill系统调用发出的。常用的信号有2号（SIGINT，可由ctrl-C发出），9号（SIGKILL），14号（SIGALARM）等等。收到信号的进程B如果没有为该信号通过signal系统调用指定句柄函数，则操作系统会按照信号的默认行为处理进程B，否则则操作系统执行进程B处理该信号的句柄函数。为了确保系统安全，操作系统必须维护进程的用户信息，以确保进程只能给其信赖的进程发信号。操作系统的超级用户是唯一一个可以给所有进程发中断信号，或者关机的用户。信号与系统调用最大的不同是，系统调用由进程发出，与硬件有关，由操作系统处理，而信号由进程通过操作系统发出，与硬件无关，是为了控制进程继续执行与否，由用户和软件处理。

#### 1.1.2 有限直接执行

进程是通过“有限直接执行”的方式执行的。大量的行动不能让进程自己执行，比如创建和删除进程、输入输出、访问内存等。为此，处理器中进程运行的模式应有两种：用户模式和内核模式。比如，用户模式中无法输入输出，而只有内核模式可以。用户模式下进程想输入输出，启动或终止进程，因page fault需要永久内存，访问文件系统，或打扰其他进程时，必须进行系统调用。

系统调用绝不能像函数调用一样直接把程序跳到某处。对于任何一种系统调用，操作系统都必须特殊地指明它的trap handler，硬件就会知道当异常情况发生时自己应该干什么。操作系统启动时，会初始化这张trap表，以给出那些系统调用的特殊地址。trap表中的地址还是间接的地址（称为系统调用号），能起到保护的作用。trap表的创建和访问都只有操作系统才能完成。

进程启动时，操作系统会为该进程建立PCB，为进程分配内存，把程序代码导入内存，建立用户调用栈和核调用栈，以原子化方式执行监督异常返回（从核调用栈中恢复用户寄存器，改变模式比特，改变pc到进程的main函数，开始执行）。进程关闭时，进程执行exit()系统调用，操作系统释放进程内存和PCB。

系统调用时，进程会经历trap过程，以进入内核模式。为了重新返回正常执行，程序必须从trap中退出，这个过程已经在3410的5.1节笔记中讲过了。这里再次强调，进入trap时，处理器（硬件）会原子化地把程序的PC、sp等寄存器以及原模式比特等存到一个每个进程都有的核调用栈中，设置好新的核内PC和sp，然后操作系统访问trap表，找到要完成的任务。退出trap时，这些核栈中存储的寄存器和模式比特等数据都会被硬件原子化地恢复，PC和sp也会被它原子化地设置好（也就是监督异常返回），进程返回原运行状态。

另一个需要操作系统通过有限直接执行的方式管控的是在进程之间不断切换的操作，这是为了实现时间分享，制造同一套硬件可以运行多个进程的假象。可以期待进程定时进行系统调用，这样操作系统就可以在调用期间把该进程暂停，但这种期待对于某些危险的进程而言是不现实的（重启？）。更安全的方式是给每个进程设置一个时间限制，一旦超时进程会中断，操作系统执行上下文切换。硬件此时将原子化地把旧进程的*用户*寄存器保存到它的核调用栈，进入内核模式，跳到操作系统中处理中断的句柄。操作系统检查中断原因，调用进程调度找到下一次要运行的新进程后，将把*核*运行时使用过的寄存器（包括通用寄存器、PC、sp和核栈指针）复制到该进程的PCB中，然后从新进程的PCB中取出其*核*运行时保存的寄存器、PC、sp和核栈指针，恢复新进程的核栈，然后让硬件原子化地执行监督异常返回，从核栈中恢复新进程*用户*保存的寄存器，返回用户模式，并把PC设为新进程原来中断时的PC。

操作系统启动时，必须向硬件指明中断的handler，以处理这种情况。操作系统也必须在系统启动之前指明每个进程的时间限制。为了防止在处理中断期间操作系统被其他进程中断，操作系统在必要时会禁用中断，但这种操作要慎之又慎，分级操作，且要考虑并行安全。

#### 1.1.3 进程调度

进程的周转时间是指其完成时刻减去到达系统的时刻，而进程的响应时间是指其开始执行时刻减去到达系统的时刻。

操作系统的调度策略用到了很多贪心算法。基础的调度策略是先到先得(FIFO)，但当某个耗时很久的进程阻挡在其他进程之前时，系统就有卡顿（周转时间长）的问题。另一种调度策略是最快者优先(SJF)。如果所有进程同时到达，最快者优先是最优的调度策略，然而如果进程不同时到达，卡顿的问题则依然存在。策略三是最快结束者优先(STCF)，这种策略在进程不同时到达的情况下成了最优。

以上的策略是在没有时间分享的情况下讨论的。然而，时间分享给了我们更充分的调度工具。我们可以让每个进程只运行一小会儿（RR），这样所有进程都能有较短的相应时间，但周转时间会受到很大影响。每个进程可以运行的时间周期非常重要，这个周期要充分长，以允许进程有实质性动作，但为缩短响应时间也不能太长。

输入输出、系统调用等会把CPU空出来。在进程调度时，操作系统就应该在CPU空出来的时候运行其他进程，以统筹的方式提高处理器效率。

一个需要解决的重要问题是，操作系统怎么能在不运行进程，从而不知道进程运行时间的情况下完成调度呢？操作系统是通过预测进程运行时间的方法完成的，这种根据程序执行情况实时调整执行的策略与缓存替换问题类似，是网络算法的应用。它建立了一个叫**多层反馈队列**(MLFQ)的启发式的数据结构。这个数据结构把进程组合进一组队列，不同的队列有不同的优先级，同一队列有相同的优先级。MLFQ有如下5个规则：（1）处理器会运行优先级最高的那个队列，（2）但每个队列中的那些进程按RR运行。队列的优先级随观察到的结果灵活变化。（3）每个进程刚进入系统时有最高的优先级。（4）如若此进程用光了属于它的那一小块时间则其优先级降低，哪怕此进程在中途离开了CPU。（5）每隔一段时间优先级全部归零。

另一种实用的进程调度策略是**比例调度**，即保证每个进程都占有一定比例的CPU时间。在每个时间周期内，操作系统给每个进程赋予一个权重，以*随机*方式加权选出本周期运行的进程。每个进程还可以给它们的子进程加权，且进程权重也不是一成不变的。这种方法既简单，又可以在进程数较多时保证调度的公平性。

#### 附录 Linux系统中的进程调度

现代Linux系统使用了一种称为“**完全公平调度（CFS）**”的进程调度方式。它的方法是测量每个进程的虚拟运行时间(vruntime)，拥有最低vruntime的进程将会被提高执行权限，这个执行权限就是著名的nice值。如果进程少则每个进程每个周期时间多，如果进程多则反之，但每个进程周期有个最低下限，这样就保证切换频繁，相对公平，同时通过设置进程切换周期下限，且设置vruntime权限，保证进程周转时间较小。

因为进程的个数可能远超千个，CFS为加快调度速度，内部的进程列按照vruntime用红黑树存储。对于输入、输出和睡眠的进程，vruntime做额外处理。

#### 拓展 多核处理器中的进程调度

多核下进程调度比单核还要困难，同样有大量的优化思路涌现出来。

思路一：单队列调度(SQMS)。所有核共用一个进程队列，每个进程运行时加锁。这样很简单，却无法适应核数目的增长，同时还无法让一个进程尽可能只在一个核上运行。为此需把一些进程移植到与用原本方法不同的核上运行，优化很困难。

思路二：多队列调度(MQMS)。每个核维护一个进程队列。这样能适应核的增长，却容易出现核负载不均衡的现象，同样需要把某些进程移植到另一个核上运行，优化也不容易。

### 1.2 内存虚拟化

每个进程都有一个地址空间作为其可使用的内存。代码、栈和堆都存在这个地址空间里。栈和堆从两个方向逐渐把地址空间填满。为了让各个进程互不干扰地分享内存，操作系统需要通过建立地址表的方式虚拟化内存。虚拟内存系统必须是不透明的、高效的、安全的。

#### 1.2.1 地址翻译

操作系统给每个进程的地址都是虚拟的，而实际的地址只有操作系统知道。操作系统通过地址翻译把物理地址翻译成每个进程的虚拟地址，以构造每个进程独享内存的假象。由于地址甚至在程序运行时也可以更改，这种分配地址的方法称为动态分配法。为了保证进程访问的地址不越界，操作系统需要存储表示进程地址开始处的寄存器和进程地址结束处的寄存器，并在进程越界时终止进程，而硬件则需要提供这些寄存器，并不允许用户模式的任何进程修改这些寄存器，从硬件角度保证安全。由此可以看到，虚拟内存的实现也体现了有限直接执行思想。

于是，在任何一个进程开始时，操作系统还要负责给进程分配一块地址空间。当进程终止时（无论正常还是非正常），操作系统要负责把这块地址空间释放。在进程切换时，操作系统还要妥善地把属于那个进程的内存保存起来。在进程发生异常时，操作系统要提供额外工具(handlers)处理这些异常。

#### 1.2.2 分页分段

为了更大限度地利用自由空间，在物理内存中可以把代码、栈和堆分段存储。因此存储一个进程的所有内存需要三对寄存器标志其内存的起始点、终止点，一个额外的寄存器标志内存生长方向、另一个额外寄存器标志可以对此内存访问的权限，包括读、写和执行。内存地址由每段的基础位置和offset组成。找寻段地址是很容易的事情，只需把段号码加上offset即可。如若超出合法内存访问范围，操作系统会终止进程访问，称为发生段错误（segmentation fault），这就保证了进程安全。

通过标记段落权限，分段还有更多的好处，比如**写入时复制**(copy on write)，即需要复制进程内存时，不急着复制内存，只复制地址表，两张地址表指向同一套地址，且这些地址都只赋予读权限。当需要写入时，再执行复制，分离地址表。COW策略在fork函数实现时起到了提高性能的作用。

分段方便了进程管理，但也会在每个段中留下大量的自由空间，可能会造成浪费。且如果段落的大小不一致，浪费的空间由于狭小且不连续更难被利用。更简单、有效和灵活的方法是让段落大小一致，这种分段方法称为分页。操作系统通过查询页码表的方式来找到虚拟地址的实际地址。*每个进程都有一个页码表*，因为为了内存虚拟化，每个进程的虚拟地址对应的物理地址都不相同。找寻地址只需把虚拟页码加上offset即可。

为了存下每个物理内存地址的虚拟地址，页码表需要变得非常庞大，且操作系统必须把它们放在内存里，这就会占据宝贵的内存空间。为了方便存储页码，系统需要为每一页存储一些额外比特：有效比特、保护比特、使用比特（是否出现在内存中）、脏比特、访问比特等等是常见的额外存储内容，这样操作系统根据这些比特就能随进程需要增减页码表的大小了。

然而即使这样页码表还是太大了。缩小页码表的算法就变得很重要。最简单的就是增大每一页的大小，但这样会增大寻址时间，造成内存浪费。第二种方式是把分页和分段结合起来——*每个进程分成多个段，每段都有一个页码表*，由于段内所有内存都是连续的，很容易在页码表中标记有效页码的起点和终点，就不用在页码表中存储无效页码了。但分段的解决方案比较复杂，且会在段外浪费很多不连续内存。页码表过大问题的现代解决方案是使用**多层页码表**。存一张页码表的页码表，第一层页码表中没有的页码在第二层中不分配内存。这样访问页码很快捷，也不用为没有使用的内存分配页码了。另一种解决该问题的方案称为**逆页码表**。与其为每个进程的每个虚拟地址建一条表的记录，不如为每个物理地址建一条表的记录，只不过这条记录还需额外记下进程的PID罢了。可以用哈希表方便通过进程PID和虚拟地址查询实际地址的反向查询，这样也能节省空间。

另一个问题是，在分页模式下访问一次内存要先访问一次页码表，等于访问两次内存！为了加快页码表访问，**翻译前视缓冲器**(TLB)成为了必需。TLB就是地址翻译缓存，它的出现让分页虚拟内存成为可能。带有TLB的地址翻译过程如下：首先，从虚拟地址获取虚拟页码，并把它扔进TLB。如果通过，则可从TLB获取实际地址，到内存中去访问。如果未通过，则硬件(x86)或者软件(RISC)需浏览地址表，慢慢找到实际地址，并更新TLB。

TLB是一种完全结合型缓存。通常TLB有一个有效位、保护位、地址空间ID、脏位等等。当进程切换时，TLB要么刷新，要么改变一个比特来标记该地址关系属于哪个进程。

#### 1.2.3 虚拟内存和内存替换

虚拟内存的“虚拟”除了指进程读到的地址不是实际地址以外，还指计算机可利用的内存（临时内存）比实际的内存还多。机制就是对硬盘（永久内存）上的地址也进行分页。当进程需要访问不在内存（临时内存）的地址时，硬盘中的相应内容需要调到内存，而内存中某些内容必须被替换以腾出空间，这个过程称为处理page fault。进程无法单独处理page fault，必须抛出异常由操作系统来完成。

选择无用内存替换到硬盘又是一个困难的问题，而这个问题与选择无用缓存替换到内存中很类似，这类问题称为内存替换，它们的解决又要用到一批贪心算法、随机算法和网络算法。常见的内存替换规则（算法）有：随机算法、先入先出算法、最不频繁使用算法(LFU)、最近最少使用算法(LRU)。LRU在大部分的情形下都最接近最优，尽管随机算法可以避免某些边角情形。严格的LRU几乎是不可实现的，所以我们只能近似LRU。硬件上可以为内存内容添加一个使用比特，每次使用该内存时使用比特修改为1，操作系统挑一个使用比特为0的内存清空，并周期性地、轮流地把所有内存的使用比特清零，这种算法称为钟表算法。

在内存替换中最需要避免的情况称为系统颠簸(thrashing)，这是指由于进程循环调用数量多于内存（缓存）帧数目的页，导致进程几乎全部的运行时间都耗费在内存替换上的现象。有的时候增加内存帧数还会让系统颠簸更严重（这种现象称为Bealy异常，只有用栈内存替换方法才会避免这种异常），所以不能仅靠增加内存帧数来解决系统颠簸。解决的方法是使用工作集模型，即周期性记录下每个进程需要的页数（工作集），如果所有进程需要的页数总和大于内存（缓存）中可提供的帧数，则暂停一个进程。工作集的大小需要操作系统实时预测，并灵活根据page fault的频率调整。

#### 1.2.4 自由空间分配

分段存储方法会在有用内存外留下大量的自由空间，如何合理分配这些自由空间，让它们不要碎片化，也是一个重要的问题。基本的方法是一分为二（malloc时）、合二为一（free时），磁盘碎片整理的原理正是如此。为了方便这两个操作，在内存获取和释放时，一般还要记录有关本次内存分配的概况信息，比如本内存块的大小。当然选择适合的内存块也有很多贪心算法，比如最小块、最大块、第一块、下一块等，甚至把常用的相同大小的内存分开存储以加快常用内存的访问速度。

#### 附录 Linux内存系统设计

Linux系统的地址空间为32位或64位。四分之三的空间归用户，四分之一的空间归操作系统。内核逻辑地址存储页码表、系统调用代码、对每个进程建立的内核栈等等。内核虚拟地址是为了解决访问内存外地址的问题的。

目前通用的x86型Linux系统的页码表为64位，设了4层页码表以层层寻址。Linux传统上支持4kB地址表，尽管现在也支持使用2MB甚至1GB为大小的地址表。Linux页码替换的算法是2Q算法：维护一个活跃队列和非活跃队列，需替代的进程是非活跃队列的最后一个，活跃队列的最后一个会被周期性地移到非活跃队列，活跃队列的长度是总页码缓存大小的三分之二。这是为了解决大文件访问的问题。

### 第1章小结

问题 | 解决方案
-|-
多个程序需要同时执行，却只有一个处理器 | 虚拟化处理器，程序抽象为进程，进程间不断切换，时间分享
虚拟化处理器时进程间要互相分隔保证安全 | 输入输出、访问内存等关键操作时进程必须系统调用
不同进程都需要尽快处理完毕无卡顿（进程调度） | FIFO, SJF, STCF, RR, MLFQ, 比例调度，CFS
多核处理器中进程调度 | 单队列SQMS、多队列MQMS、移植
进程的内存要安全分配、分隔 | 虚拟内存（虚拟地址、地址表）、将进程地址分页分段、页码+offset存储
自由空间高效分配 | 一分为二、合二为一、最小块、最大块、第一块、下一块、分开存储常用大小内存
页码表访问内存次数变多 | 使用TLB，加快简单情形访问
页码表存储空间过大 | 增大页码表大小、分页分段结合、多层页码表、逆页码表
利用内存以外的存储空间 | 通过虚拟内存为硬盘分配页码表
某些内存需被替换到硬盘上或某些缓存需要被顶替（内存替换） | 随机、FIFO, LFU, LRU，近似LRU、钟表算法
内存替换导致系统颠簸 | 工作集模型，及时暂停某些进程
处理page fault | 操作系统系统调用

## 第2章 并行

本章我们主要讨论一个进程是如何被剖分成多个线程，从而在一个或多个处理器上并行运行的。需要注意的是，由于系统调度器可以不停地在不同线程间切换，在单机上也可以有并行。

### 2.1 线程与并行

一个进程可以分成多个**线程**，这些线程拥有不同的PC、不同的内存栈等等，唯一相同的是它们共享内存地址空间，即它们只有一套数据（特别地，所有线程共用一个堆，称为共享内存）。如果几个线程在同一个处理器上运行，线程之间必须不停切换，只是切换时不需要单独存储原有线程的地址空间了。

特别需要注意的是，在一个线程内的代码，会保证被顺序执行，但不在一个线程内的代码不保证能顺序执行。当进程运行时，线程运行的顺序是不可确定的——都是由操作系统调度器决定（操作系统调度不仅决定进程调度，也决定线程调度）。任何一个线程在执行到任何一个语句时都可能被中断切换到下一个线程。这种执行的不确定性是导致并行编程困难的最大原因。

由于线程共享内存，线程可能会阻塞对方完成其应有的任务，这种情况称为竞争执行。为了防止竞争执行，我们必须限定某线程的某段代码执行时不能被中断，即保持这段代码的*互斥性*（原子性），这种被原子化的代码称为事务(transaction)。锁是实现互斥性的工具。

另一种我们可能需要维持的性质是*顺序性*，即告诉不确定的系统调度器：某线程的某段代码必须在另一线程的另一段段代码之前执行。条件变量是实现顺序性的工具，而锁和条件变量又都是一种叫信号量的机制的特例。

### 拓展 用户线程

以上所说的线程都是内核线程，其创建和调度都是由操作系统调用和调度器控制的。内核线程的切换与进程切换类似，一样需要存储寄存器，PC，内存栈等（存储在线程控制单元(TCB)里），只是不需要存储内存堆了。另一种可行的线程是用户线程，即用户库软件提供“线程”的创建、调度和切换功能，这些功能无需系统调用。这种线程切换、调度等比起操作系统切换、调度更加高效。当某用户线程需要输入输出等系统调用时，操作系统还是应该提供一批内核线程库，供这个用户线程系统调用使用，此时内核还会通知用户线程调度器此线程已进入系统调用，可以调度其他线程执行了。当内核线程库被创建、改变时，操作系统应及时通知用户线程调度器。

### 2.2 锁

#### 2.2.1 锁的实现

实现事务原子化的基础机制是**锁**，它是一个由硬件和操作系统提供给软件的接口。当某线程第一个请求某锁时，它将拥有这把锁，然后执行被锁住的代码。其他线程若想获得*这把锁*（可以同时有很多锁存在），执行被*这把锁*锁住的代码，则必须等待第一个线程退出。当该线程退出时，所有等待线程中的一个将会被通知，它将获得这把锁，从而可以执行它被锁住的代码。通过锁可以保证关键代码的原子性（异步执行），从而在操作系统混乱不可预知的调度下保证关键代码的执行有序。

以上所谈论的锁都是互斥锁（mutex），它是其他锁的基础。实现互斥锁的关键之处在于实现互斥执行。最简单的互斥执行方式是暂停所有对该线程的中断，但很不幸的是，坏线程会利用这点运行无穷循环，从而导致系统崩溃，因此这种锁只在操作系统内部有少量的使用。第一个有效的锁是Test & Set自旋锁，即在尝试占有锁时，通过硬件支持把test & set变成一个不可拆分的原子表达式，这样就不会在线程运行到关键时刻时有其他线程被调度进来。自旋锁的“自旋”指的是若此锁正在被别的线程占据则本线程做死循环。自旋锁不是公平的锁，在单机上非常浪费，但在分布式系统上如果关键时刻做的操作不多，性能还不错。与之类似的算法还有compare & swap, load linked & store conditional, fetch & add等等（代码可以参考附录），这些都是自旋锁。

自旋锁在性能上有巨大的缺点——未能占有锁的线程做死循环浪费了大量的钟周期。除了fetch & add以外的其他自旋锁还不能保证每个线程都会被执行（不公平）。为了不用死循环实现锁，操作系统必须提供软件支持，即给线程提供某些系统调用，使其能有限地控制自己或其他线程的调度——要么把自己调出去（wait或park或sleep），要么宣布某些把自己调出去的线程可以执行(notify或unpark或wake)，这些锁称为wait锁。为了确保每个想要锁的进程最终都会执行，锁还应该维护一个线程队列，挨个执行线程队列中的线程，确保锁对所有线程的公平性。将自旋锁和wait锁结合起来有时能获得更好的性能，比如Linux的futex锁就是两者的一个结合。

锁实现中一个特殊的竞争执行是wakeup/waiting竞争执行，即A线程醒来时B线程正在准备睡觉，导致B线程无法收到锁已经被释放的信息，B很可能永远睡下去，无法获得锁。解决的方法是操作系统需提供一个新系统调用，让B线程能通知操作系统它将准备睡觉，当A线程广播其释放锁的信息时，B线程可跳过睡觉步骤，直接尝试得锁。

#### 2.2.2 以锁为基础的并行数据结构

为线程加锁可以让数据结构线程安全。本节我们会讨论如何为一个并行数据结构加锁使之线程安全，且能利用并行提高运行效率。

最简单的并行安全机制就是给所有的重要代码都加锁。一种叫监视器的设计方式甚至让所有与该对象有关的方法使用时自动加锁。不幸的是，加锁的成本很高，尤其在分布式系统上还与网络连接有关，对性能有很大损失。我们以并行安全的计数器为例，阐述一种更高效的可以用在分布式系统上的用锁方法，这种计数器称为近似计数器——每台机器上都有一个计数器，它们自己计算时不停地加锁，但它们都会定时地向一个总计数器汇报（自然汇报的过程需要另外加锁）。总计数器的值是近似值，汇报的频率越高，总计数器的值越准确。这样把计算的工作分担到了各台机器上，又尽可能减少了各台机器之间的通信，提高了分布式系统的性能。

在设计并行安全的数据结构时，我们必须注意（1）加很多锁有时会适得其反，因为加锁是有成本的。（2）一定要注意所有线程可能的起始点和终止点，用锁把好每一道关口，尤其在异常之处绝对不能忘记释放锁。（3）只有当性能问题出现时我们才需要考虑解决它，正确比性能更重要。

### 2.3 条件变量

#### 2.3.1 条件变量的实现

在多线程编程中，我们经常需要等到某些条件成真之后再继续执行，而**条件变量**就是实现这种需求的机制。条件变量有两个语句：wait和signal。当某线程走到某条件变量的wait时，它会自动睡眠，直到另一个线程走到该条件变量的signal，则原线程才会继续执行。条件变量必须与锁一并使用，使用条件变量的wait前必须上锁（一般来说signal也要），否则会出现wakeup/waiting竞争执行。条件变量使用时还应注意用while循环包裹条件变量，而while循环的终止条件一般为一个普通变量done。

条件变量可用一个队列和保护该队列的一个自旋锁实现。wait实现的方法是让该线程进入属于条件变量的队列，然后让该线程睡眠，并释放通过函数参数传来的锁。当wait函数中的线程被唤醒时，wait会重新获得被传进来的锁。signal与之相反，会把线程队列中的一个拿出来，并让这个线程继续执行。

在Java当中，条件变量称为wait/notify机制。除了整个程序中只能有一个条件变量以外，其余与这里讲的POSIX的wait/signal条件变量没有不同。

条件变量实现中会遇到两个问题：第一，当线程1等待时，线程2发了信号，是线程1应该立即执行，还是线程2应该执行完其剩余的内容？前者称为Hoare semantics，而后者称为Mesa semantics。现代大部分系统采用的都是Mesa semantics，尽管Java语言实现监视器的notify/wait方法与两者都有[不同](https://cseweb.ucsd.edu/classes/sp16/cse120-a/applications/ln/lecture9.html)，把决定该问题的权力直接交给系统线程调度。第二个问题称为条件覆盖。当有多个线程等待，且另一线程发送信号时，唤醒队列中的第一个线程是否合适？Lampson和Redell认为，所有的线程都应该被唤醒，先到先得，即把signal换成broadcast（POSIX），或把notify换成notifyAll（Java）。

#### 2.3.2 条件变量的作用

条件变量能够解决很多问题。类似于在3110中学过的promise的作用，条件变量可以保证两个线程可以以一定的顺序执行。join问题是指让父线程生成子线程，且让子线程结束后父进程再结束的问题，这个问题可以用条件变量解决，且应该用一个普通变量done协助完成。producer/consumer问题（或称bounded buffer问题）是指一类线程为producer，一类线程为consumer，producer往有限的缓冲区存储数据，consumer从缓冲区拿出数据，要保证这种操作线程安全的问题。可以使用两个条件变量和一个公用互斥锁解决这个问题。

### 2.4 信号量（Semaphore）

#### 2.4.1 信号量的定义和使用

Dijkstra在二十世纪六十年代就提出，锁和条件变量实际上是一种对象的特例，这种对象称为**信号量**（semaphore）。一个信号量由一个整数值和两个函数wait和post组成。wait函数把信号量的值减少1，且当信号量的值为负时等待。post把信号量的值增加1，且如果有线程在等待，就喊醒其中一个进程。

一个初始值为1，且wait和post中间放入关键语句的信号量等价于一个互斥锁，这种信号量称为二元信号量。改变二元信号量的初始值，我们可以用信号量实现允许多个线程同时执行，但线程总数不能超过容量的非互斥锁。

把wait语句看成条件变量的wait语句，把post语句看成条件变量的signal语句，则一个信号量可以实现条件变量。更深刻的是，使wait条件满足的done为多少，这个信号量的初始值就是多少。通过锁和条件变量的例子，我们可以理解信号量初始值的含义：*信号量的初始值就是允许访问、使用的资源个数*。初始值为1则只允许访问1个资源，初始值为0则不允许访问任何资源。

以信号量为工具，可以解决大量的并行问题。读写锁、吃饭的哲学家等问题只是其中的一小部分例子（代码见附录，更多问题请参考[这个网站](http://greenteapress.com)）。在使用信号量编程时，要特别注意死锁问题：不同于条件变量中的wait函数，信号量的wait函数不会自动释放其他二元信号量产生的锁，因此很容易导致死锁。

#### 2.4.2 信号量的实现

信号量可以实现锁和条件变量，而使用一个互斥锁、一个条件变量，和一个表示信号量值的整数，也能实现一个信号量。不过用信号量实现条件变量并不是特别容易。

### 2.5 常见的并行错误

并行实现中经常会出现错误。常见的并行错误有：

* 违反原子性。某些应该原子化的代码没有加锁，线程在意料之外的地方被调度器切换。解决办法是加锁。

* 违反顺序性。某段代码永远应在另一段代码前执行，但实现时忘记了这一点，调度器以意料之外的顺序安排了线程。解决办法是加条件变量。

* 死锁。这是指因线程调度切换，导致线程a拥有锁a，想获得锁b，而线程b拥有锁b，想获得锁a，可两者都无法得锁的情形。广义的死锁又称为循环依赖。解决办法有以下几种：（1）给所有的锁拓扑排序。一个很好的排序方法是按锁的内存地址排序。（2）在得锁的环节外再上一个锁，保证在某线程得锁期间不会被调度中断。但这种方法会减少并行。（3）线程a如果得不到锁b就放弃锁a，然后重来。但这种方法会导致活锁问题，即线程a和b都在不停尝试得锁却无法得到。（4）不用锁实现原子性，即利用硬件提供的compare & swap等原子表达式，巧妙地让关键代码一行完成。（5）让线程调度器提前分析有没有可能有死锁，让有可能死锁的线程顺序执行；或者使用银行家算法，巧妙排列线程执行的顺序，先让需要资源少的线程执行，执行完就会释放其所有资源，这样可以通过合理调度让每个线程执行时都有其需要的资源。但性能会因此受到损失。（6）如果死锁非常罕见，当发现死锁问题后，重启、回滚系统也是一个选择。

### 拓展 基于事件的并行

本章之前部分讲述的并行都是基于线程的并行，但还有另一种并行机制，即基于事件的并行机制。这个机制简单情况下只在单机上适用，只有一个线程（主线程），不需要锁。事件机制把需要完成的任务抽象为**事件**(event)。主线程中处理事件的函数称为handler。主线程运行时会通过无穷循环查看有没有事件，可以通过select或poll系统调用定时查看事件是否存在，也可以用listener pattern，即接收UNIX系统中的中断信号来处理事件，还可以通过注册callback的方式，强制性地让handler在事件发生之后完成。

事件并行的最大问题在于，任何系统调用都可能阻塞事件的处理。因此在handler中需要禁止任何导致中断的系统调用，比如输入输出等。为了解决事件并行要求输入输出的问题，现代系统中都提供了*异步输入输出*的功能。我们在3110中已经学过的promise，就是一种异步输入输出的前端接口。

## 第3章 文件系统

本章我们主要讨论操作系统如何管理输入、输出、永久存储设备和永久存储的内容。

### 3.1 输入、输出和存储设备

#### 3.1.1 输入和输出

在3410的5.3节中，我们已经学过了输入和输出设备，也简要讨论了polling和中断两种涉及系统的输入输出方式。polling适合短时的、需要处理大量信息的输入输出，可以避免频繁切换导致的“活锁”现象，而中断适合长时间的，缓慢的输入输出，可以最大限度利用CPU效能。为了加速内存与硬盘间的连接，一个特殊的称为DMA（直接内存访问）的设备可以专门处理从内存到硬盘的数据传输，从而让CPU能够有更多时间空闲。汇编语言通过IO指令或者内存映射IO与操作系统输入输出管理交互。

一个重要的问题是，如何让很不相同的输入输出设备与同一个操作系统用相同的指令交互呢？解决方案是操作系统为每个输入输出设备准备一个**驱动器**，使驱动器与操作系统基本输入输出框架连接。有趣的是，在Linux操作系统内核的数百万行代码中，超过70%是驱动器代码。大部分驱动器的代码分四个步骤：（1）等待设备正常工作；（2）把数据、命令写进寄存器，开始输入输出；（3）等待输入输出完成，传输数据；（4）处理中断和错误。

#### 3.1.2 磁盘简介

磁盘是目前最通用的廉价存储设备。一个磁盘是由一个大量覆盖磁性物质的同心圆构成的金属片。磁头通过旋转改变其寻址的同心圆半径(seek time)，金属片也在旋转以让磁头读到某同心圆上的地址位置(rotational time)。然后磁头通过改变那个地址的磁性或感应那个地址的磁性来写入或读取数据。

与操作系统进程调度类似，不同的读写请求也需要调度，这就是磁盘调度。电梯算法是常见的磁盘调度算法，即不止因seek time最小就来回摆动，从而忽略某些需要更大seek time的请求。总的来说，磁盘内部的寻址机制会保证最短寻址时间的请求优先。当然操作系统（驱动器）在向磁盘请求时也应该做一些优化，比如IO合并，等待再发送请求，预先调度处理等。

#### 3.1.3 冗余便宜磁盘组（RAID）

如何制造一个庞大、快速、可靠的存储系统呢？RAID是一种把多个磁盘组合起来，并且包含自己的处理器和内存的大型存储结构，而它在外表上看起来与一个大磁盘没什么两样。每个在它内部的数据都有备份，因此一个磁盘坏掉并不会影响RAID的工作。RAID有内存、缓存和处理器优化内存分配，因此寻址比单个磁盘快速，且多个磁盘组合可以让RAID非常庞大。

磁盘存储的基本单位是“块”(block)，一般大小为4KB。为了方便在读取大文件时并行，RAID一般会把大文件分成多个“片”(chunk)，每个片含有多个块，不同的片存在不同的磁盘上，同一个片存在同一个磁盘上。更大的片能减少寻址时间，但也会减少并行带来的性能优势。

评价一个RAID有三种标准：容量、性能、可靠度。以下给出了不同种RAID的性能评价。其中吞吐量依次为顺序读、顺序写、随机读、随机写，响应时间依次为读、写。

型号 | 特点 | 容量 | 可靠度 | 吞吐量 | 响应时间
-|-|-|-|-|-
RAID0 | 每条信息都只存储一份 | NB | 0 | NS,NS,NR,NR | T,T
RAID1 | 每条信息都存储两份 | NB/2 | 1 -> N/2 | NS/2,NS/2,NR,NR/2 | T,T
RAID4 | 一个磁盘专门存储校验码 | (N-1)B | 1 | (N-1)S,(N-1)S,(N-1)R,R/2 | T,2T
RAID5 | 磁盘交替存储校验码 | (N-1)B | 1 | (N-1)S,(N-1)S,NR,NR/4 | T,2T

#### 3.1.4 固态硬盘（SSD）简介

固态硬盘作为一种新型存储设备，正在逐渐取代传统磁盘作为存储的主流。目前采用的固态硬盘技术称为闪存，这在3410的第1章和第4章都有介绍。一个SSD能提供三个操作：读（10微秒），擦除（数毫秒），写（100微秒）。需要注意的是，为了向闪存中某页写入，必须把一个内存块都擦除。而且一个频繁写入的页会被逐渐击穿（额外的电荷会在块内集聚，直到0和1无法被区分）。操作系统写固态硬盘驱动时，应该注意到固态硬盘的这些性质。

固态硬盘的读取和写入一般采用日志方法，即依次地往实际地址中填入内容，写入请求指定的地址作为虚拟地址，维护一张虚拟-实际地址对应表。日志方法能均衡击穿效应，且并不会因擦除一大块内存块而丢失数据。日志方法的缺点主要有：（1）会产生大量的垃圾，即后写入的内存依然是按日志方法依次写入的，而前面写入的内存就成了垃圾。这样就需要不停地处理垃圾，即找到一个含有垃圾的页，将里面不是垃圾的数据写入日志，然后全部擦除。（2）地址表太大了。这可以参考1.2.2节中提出的页码表解决方案解决。（3）垃圾处理不一定能均衡击穿效应。如果某块所含数据一直有效，那一块就永远不会被清理。为此，这些块需要被不停地重写。

### 3.2 文件系统

永久存储在操作系统实现中具有重要意义。尽管计算机执行其计算主要是往内存读写，如若需要永久存储还是需要往硬盘读写。硬盘中的存储数据如何组织和管理是文件系统研究的主题。

#### 3.2.1 文件和文件目录

一个**文件**(file)就是一个可读、可写的字节数组。在操作系统层级，文件就是*存储在硬盘*（注意不是内存）上信息的基本单元。一个**文件目录**(directory，简称目录，或称文件夹)是一个特殊的文件：它存储了一张用户文件名与低级文件名之间的键值对表。这里的“用户文件名”可以是文件名，也可以是其他文件目录名。以此为基础，文件目录以树形结构存储。文件目录从根目录开始，在Unix系统中以"/"表示。同一个文件目录中的文件和文件目录不能重名（尽管可以有一个文件叫foo，另一个目录也叫foo，而且只要不同文件在不同的目录下就可以重名，也即文件目录是个命名空间）。文件的类型是通过文件的扩展名显示的，尽管操作系统没有强制某文件以某扩展名存储的机制。

在Unix文件系统中，创建文件操作完成了两件事情：（1）构造了属于文件的inode；（2）把这个inode与用户指定的名字链接(link)在一起。一个inode可以有多个名字，把新名字与旧名字链接的shell命令为ln。注意目录是不能创建链接的，这是为了防止文件树中出现圈。符号链接是另一种把一个名字链接到另一个文件的方法。符号链接与链接的区别是当源文件删除时，若链接存在则源文件并没有被删除，仍可使用，而符号链接无法使用。

Unix文件系统采用了一些权限比特控制文件的读、写和执行权限。它把用户分成三种权限：创建者、同组者、全部用户，而文件的创建者或root可通过chmod命令改变文件权限。

#### 附录 Unix中与文件有关的系统调用

系统调用 | 属性
-|-
open | 创建文件，此调用确保它只可以被写入，且若此文件存在则把文件内容清零。打开文件后会返回一个数，称为文件描述。一般来说该数从3开始，这是由于0是标准输入文件，1是标准输出文件，2是标准错误文件。
read和write | 向某文件描述读和写，注意读写完成后的光标位置发生了改变
lseek | 随机访问某文件某比特（即改变光标位置）
dup | 在用fork创建新进程时可以起到复制文件描述的作用
fsync | 强迫操作系统把所有还未写入硬盘的数据都写入硬盘
rename | 原子化地把文件重命名
stat或fstat | 查看文件的通用信息
mkdir | 创建目录。这个目录开始时只有两个元素：自己和上一级目录。
opendir,readdir,closedir | 获得、读取和关闭目录
rmdir | 删除一个空目录
unlink | 删除一个文件，即解绑创建文件时构造的链接。

#### 3.2.2 文件系统实现

文件系统是在硬盘上实现文件管理的操作系统部分。大部分文件系统会把硬盘分块，留下其中一部分块存储inode,各块是否正在被使用(bitmap法)，和本文件系统信息。其中inode又称索引节点，存储着文件的长度、权限和地址。为了存储文件的地址，inode存放了大量文件的指针，当然也可以存放指针的指针，即文件地址的多层索引。每个inode有一个编号称为inumber，这个inumber就是目录中存储的低级文件名。文件目录是一个特殊的文件，因此文件目录也有自己的inode。

当用户提出打开文件的要求时，文件系统首先会去找到该文件的inode。为了这么做，文件系统首先会找到根目录的inode（它的inumber是2），找到它的目录，在目录中找到下一级目录的inumber，然后走到下一级inode，以此类推。在这个过程期间文件系统还要查看或更改这些inode的bitmap，来查看哪些块是自由的或者已经被分配。最后，文件系统会把文件的inode读入内存。一旦打开文件后，用户就可以通过read系统调用读取文件，改变光标位置，并关闭文件。由于输入输出的操作特别多，某些系统采用缓存的方式加速文件处理操作。

以上的文件系统有很多缺点，特别地，由于inode和文件数据分开存储，对于很常用的inode操作磁盘要多转好多圈。FFS是第一个把磁盘结构考虑进去的文件系统。它的对外函数调用仍然是open等等，但其内部磁盘的存储结构发生了改变：把磁盘空间分块，让文件的inode接近该文件的数据，让同一目录下的文件相互接近，利用局域化原理加速常见文件访问情形。对于大文件，FFS把它们分到不同的块去，这样就不至于出现一个磁盘块全部被一个文件占据，从而无法局域化优化的问题。FFS还把小文件存到缓存去，通过计算减少磁盘圈数，并允许长文件名和符号链接，这些优化让文件系统更加高效。

#### 3.2.3 高可靠

作为管理永久存储的软件，文件系统还应该有很高的可靠性，即在读取或写入信息时若发生断电或操作系统崩溃，则文件系统中的数据应该自恰——要么完成任务，要么回滚到初态，不应该出现某任务完成一半的情况。

目前高可靠文件系统主要有以下三种设计：

* FSCK设计。即在恢复时检查磁盘中的所有文件是否自恰，包括inode指针是否有效、inode权限是否正确、是否有重复指针、检查目录等等。此方案对正常工作没有影响，但恢复时间太长了。

* WAL设计。即先向日志写入关于此次写入恢复的必要信息，比如inode等等，然后向内存写入（当然最后最好还要向日志确认已经完成）。当发生崩溃后需要恢复时，所有写入日志的操作都会被重新读取恢复，而没有写入日志的操作则会被忽略。比起永久内存来，日志的空间很小，而且经确认完成的事务都会被从日志中擦除。大部分高可靠系统都采用这个设计。

* COW设计。不急着更改文件内容，而是把新内容依次写到永久存储中的空闲地区（类似于SSD驱动），过一段时间再把新内容更新。这就是LFS文件系统的主要思想。通过*依次批量写入*，LFS避免了磁盘的大量运动，从而提高了文件系统性能。LFS把inode的地址存在一张叫imap的表里，并在较长时间间隔内更新imap表。LFS的缺点是需要垃圾处理；但需要版本控制的系统不需要垃圾处理，还需要把以前的版本留下作为“快照”，因此COW成了版本控制(例如git)的实现方法。当遇到系统崩溃时，LFS会去检查两个事务的timestamp是否自恰，若不自恰则回滚。值得注意的是，WAL、COW等点子都最先来自数据库研究，文件系统的设计与数据库的设计大有异曲同工之妙。

#### 3.2.4 数据保护

磁盘中存储的比特很可能会因老化而丢失，文件系统应该考虑到并解决这个问题。一般的方式是给数据加上一个用某种函数算出的校验码，只要检查该校验码是否正确即可。校验码会多存储一些空间，且检查校验码的过程耗时比较长，一般应该在晚上周期性地扫描磁盘校验处理。

### 3.3 分布式系统——以分布式文件系统为例（拓展）

分布式系统即多台机器以网络连接实现同一个功能的系统。本节后的附录简略地列举了有关网络的知识，这里需要强调的是：网络是一个从根本上不可靠的系统。再加上分布式系统中机器的故障特别频繁，如何设计一个可靠和可延展的多机系统是这里讨论的主题。这里仅以分布式文件系统中的NFS和AFS为例讨论。

NFS为了能很快地从故障中恢复，设计时保持命令的无状态性（每个命令都包含需要执行此命令的全部信息，这样恢复后服务器就不需要再去寻找已经丢掉的状态）和幂等性（idempotency，多个重复请求和一个请求效果相同）。分布式文件系统还会遇到3410笔记5.2节中讲到的缓存自恰问题，NFS通过脏读必须回应、关闭文件必须更新、定时查看文件是否被更新等方式解决了缓存自恰问题。

AFS为了方便系统延展提高性能，规定当打开文件时，整个文件都会到用户端，之后所有的操作都利用本地文件系统；并注册了一个callback，当缓存被更新时服务器将通过callback通知用户端；关闭文件时，用户端向服务端更新。AFS的缺点是从故障中恢复需要大量的用户服务交互。目前NFS是通用的分布式文件系统，但它的新版本正吸纳AFS的功能。

## 附录 计算机网络简介

网络是不同机器上进程与进程之间交换信息的机制。目前通用的网络架构为五层架构，从下至上分别为物理层（physical layer, 有线，无线，传输比特）, 连接层（link layer, Ethernet, Wifi，传输帧）, 网络层（network layer, IP，传输包）, 传输层（transport layer, TCP，UDP，传输片段）和应用层（application layer, HTTP，FTP，DNS，传输信息）。End-to-end观点指出，一个应用只能在最高层检查是否正确，而底层机制不提供能够完成任务的严格保证。这个观点孕育了现代网络的基础：信息传递的不确定性。

* 应用层。应用层的协议主要有HTTP，SMTP和IMAP等电子邮件协议，和DNS域名解析。域名解析是以等级形式递归地在其他服务器上完成解析的，先解析根域名，再解析前面的域名。域名解析的目标就是把人类可读的自然语言域名翻译成需要连接的IP地址。域名解析污染和轰炸是常见的网络攻击模式。

    应用可以通过函数调用的方式访问网络，称为远程函数调用(RPC)。服务器会通过某种协议（比如HTTP）接受某类函数调用请求（比如常见的GET和POST函数调用），而用户则会通过同样的协议发送函数调用请求，最后服务端也会返回函数调用的结果（比如201，404等等）。客户端和服务端的应用可以通过RPC调用相应端的句柄（stub），句柄先对函数进行编译，再通过系统调用控制网络，进而可深入传输层及以下传递信息。函数参数和指针的传递比较复杂，句柄编译器需要把内存等序列化(serialize)，变成统一格式，再打包送出，有时还需要服务端反过来调用用户端获得内存。

    为了与另一台机器的某个函数建立联系，并让对方知道自己的来历，应用层需要指明对方的端口号，并通过socket包裹自己的端口号。HTTP的端口号一般是80，其他通用的应用层协议都有自己常用的端口号。中继机器会把A的IP地址:端口号与B的IP地址:端口号对应起来，建立连接。

* 传输层。传输层的协议主要有TCP和UDP，这也是两种socket编程的方式。UDP不保证连接可靠，不保证比特会顺序到达，不保证不会发生线路拥堵，处理不可靠连接的任务都落到了应用头上，但UDP简单快速，适合实时传播视频，有时也适合实时传播音频等。TCP保证连接可靠，这是通过三重握手、用户端存储正在发送中的包、把几个包绑定用流水线发送、和服务端为每个用户建立专门socket的方式实现的。为保证对方收到且只收到一次有效包，TCP所有数据包送出时都有本程序中唯一属于此包的编号，供接收方查验。

    最值得注意的是TCP管制流量、控制拥堵的方法：如若包被全部收到，则下一周期一个流水线可以多送一个包，或者timeout时间减小一点（带宽线性增加）；如若包有丢失，则下一次一个流水线可送的包减半，或者timeout的时间翻倍（带宽指数衰减）。

* 网络层。网络层的协议主要是IP，是通过IP地址发送数据包实现的。每个包在这一层都会加上起点和终点的IP地址（马上就会被翻译成MAC地址）。获得自己IP地址的方法主要是DHCP，每台电脑通过与路由器(router)以DHCP形式连接，就能逐级获得自己在内网和外网中的IP地址。为节约IP使用，路由器还可以翻译（通过NAT协议）内网和外网的地址（把一个IP通过加后缀的形式造出多个IP）。路由器还需要通过ARP协议，把自己和对方的IP地址翻译成自己和对方的MAC地址。路由器还要控制每个包需要发向何处，并真正发出或接受每一个经手的数据包。可以通过路由之间连接，或路由与中央路由器递归连接，再加上网络流算法实现寻址计算。

* 连接层。以太网(Ethernet)是本层的架构，这一层的主要硬件是交换机(switch)。路由器会把包发给交换机，然后交换机会通过总线（物理层）发给其他交换机和路由器。交换机会通过数据包两端的MAC地址确认把包发到哪个交换机的哪个端口。

* 物理层，即信息真正在光纤或电波中传递，需要从交换机中收取并向另一个交换机发送。略。
